# Элементы машинного обучения([Слайды](https://www.dropbox.com/s/h1r9iju8i1c1gyp/Lecture%202%20-%20Machine%20Learning%20-%20annotated.pptx?dl=0))

Supervised Learning - обучение с учителем

Хорошая модель должна не просто хорошо приблежать тренировочные данные, а предсказывать тестовые

## Метод ближайших соседей

Train: просто запомнить

Predict: найти ближайший и выдать его класс

Метрики расстояний:

![formula](<https://render.githubusercontent.com/render/math?math=L_2=\sqrt{\sum_{i}{(v_i-u_i)^2}}>)

![formula](https://render.githubusercontent.com/render/math?math=L_1=\sum_{i}{|v_i-u_i|})

Имеет 100% точность на тренеровочных данных

## Метод k-ближайших соседей (K-nearest neighbors, K-NN)

Как предыдущий, но выбираются k соседий и предсказание определяется по большенству

Гиперпараметры(hyper parameter) - параметр который выбирается вне процесса тренировки и не меняется в процессе тренеровки

## Переобучение и недообучение (Overfitting vs Underfitting)

![](images/2020-09-24-15-08-39.png)

Очень сложно вывести баланс

Как выбрать K для K-NN(и гиперпараметры вообще):

- Выбрать k=1 для 100% точности для train(плохо, переобучение под train)
- Выбрать лучший k для test(плохо, переобучение под test)
- Разбить данные на 3 датасета (train, val(валидационный), test), выбрать лучший k для val, а оценивать по train
- Кросс-валидация(Cross-validation): Разбить выборку на N частей и натренеровать модель N раз(каждый раз выбирая разную часть как тест), усреднить точность, подбирать оптимальную K

test часто называют holdout

## Стандартные метрики качества

### Бинарная классификация

**Точность**:
![formula](https://render.githubusercontent.com/render/math?math=Accuracy=\frac{correct}{total})

Проблемы:

- плохо работает при несбалансированных классах
- не учитывает стоимость ошибки

**Precision**:
![formula](https://render.githubusercontent.com/render/math?math=Precision=\frac{TP}{TP%2BFP})

**Recall**:
![formula](https://render.githubusercontent.com/render/math?math=Recall=\frac{TP}{TP%2BFN})

![](images/2020-09-24-15-35-02.png)

**F-score**:
![formula](<https://render.githubusercontent.com/render/math?math=F_1=\frac{2}{\frac{1}{precision}%2B\frac{1}{recall}}=\frac{2*(precision*recall)}{precision%2Brecall}>)

### Многоклассовая колассификация

**Точность**:
![formula](https://render.githubusercontent.com/render/math?math=Accuracy=\frac{correct}{total})

Confusion matrix:

![](images/2020-09-24-15-41-56.png)

![formula](https://render.githubusercontent.com/render/math?math=Precision_c=\frac{A_{c,c}}{\sum_{i=1}^{n}{A_{c,i}}})

![formula](https://render.githubusercontent.com/render/math?math=Recall_c=\frac{A_{c,c}}{\sum_{i=1}^{n}{A_{i,c}}})

По сути чтобы посчитать Precission надо поделить значение клетки confusion matrix на сумму значений в строке, а для Recall в столбце

![formula](https://render.githubusercontent.com/render/math?math=Precision=\frac{\sum_{c=1}^{n}{P_c}}{n})

![formula](https://render.githubusercontent.com/render/math?math=Recall=\frac{\sum_{c=1}^{n}{R_c}}{n})

Так же можно посчитать ![formula](https://render.githubusercontent.com/render/math?math=F_1)

Все эти метрики надо максимизировать

## Machine Learning Flow

### Разбить данные на train, val и test

Проверить ошибку на train, если она большая то нужно(underfitting):

- Взять более мощнеую модель
- Взять боьше ресурсов для тренеровки
- Использовать другой подход

Проверить ошибку на val, если она большая(overfitting):

- Взять больше данных
- Взять больше регуляризации
- Использовать другой подход

Проверить ошибку на test, если она большая:

- Отличаются train и test
- Взять больше данных, таких как test
